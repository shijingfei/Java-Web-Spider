​	设计一个网络爬虫来下载网页，分解网页，遍历网络，存储主要信息 。用**httpcomponent**来通过 HTTP 协议来访问网络资源 ，用**Jsoup**来解析html的信息，将需要的信息存储到MySQL数据库中。在访问网络时采用带有偏好的宽度优先搜索，设置避免重复。

​	第一步的目标是爬取文本信息，通过分词来提取关键词。进一步的目标是爬取图片及其标签。对于设置反爬虫的网站，考虑做DNS缓存和设置多个代理IP 。

​	判断网页的重要性的因素主要有链接的欢迎度、链接的重要度和平均链接深度、网站质量、历史权重等主要因素。链接的欢迎度主要是由反向链(backlinks，即指向当前 URL 的链接)的数量和质量决定的。 